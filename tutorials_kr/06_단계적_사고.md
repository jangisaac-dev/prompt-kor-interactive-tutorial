# Anthropic Prompt Engineering 101 - Part 6: 단계적 사고 (Precognition & Thinking Step by Step)

> **Thumbnail Prompt:** A digital brain with complex gear systems and glowing neural pathways, a translucent notepad floating beside it with handwritten logical steps, high-tech laboratory background, cinematic lighting, 8k, hyper-realistic.

## 1. 단계적 사고(Precognition)란?

자고 있는 수학 천재를 새벽 3시에 흔들어 깨워서 "234 곱하기 567이 뭐야?"라고 묻는다고 상상해 보세요. 아무리 천재라도 비몽사몽한 상태에서 즉답을 요구받으면 틀린 답을 낼 확률이 높습니다. 하지만 "잠깐 정신 좀 차리고, 여기 종이랑 펜 줄 테니까 천천히 계산해 봐"라고 한다면? 그는 완벽한 정답을 맞힐 것입니다.

Claude와 같은 LLM(Large Language Model)도 이와 정확히 똑같습니다. 모델에게 즉각적인 답변을 강요하는 것은 '비몽사몽한 천재'에게 정답을 내놓으라고 재촉하는 것과 같습니다. Anthropic은 이를 **'Precognition'** 혹은 **'Thinking Step by Step'**이라고 부릅니다. 모델에게 **"단계적으로 생각할 시간(토큰)"**을 주는 것만으로도, 복잡한 추론 문제에서의 성능은 드라마틱하게 향상됩니다.

## 2. 핵심 원칙: "Thinking only counts when it's out loud"

단계적 사고의 가장 중요한 규칙은 **"생각은 반드시 밖으로 드러나야 한다"**는 것입니다.

### 왜 '입 밖으로' 내뱉어야 할까요?

LLM은 근본적으로 '다음에 올 단어(토큰)'를 예측하는 자동 완성 기계(Autoregressive Model)입니다. 모델이 생성하는 모든 토큰은 그 자체로 모델의 '작업 기억(Working Memory)'이 됩니다.

1.  **모델 내부 사고 ≠ 출력된 사고**: 모델이 내부적으로 엄청난 연산을 수행하더라도, 그것이 텍스트로 출력되지 않으면 그 연산 결과는 다음 토큰 생성에 전혀 반영되지 않습니다. 즉, 모델은 '속으로' 생각하는 능력이 없습니다.
2.  **연쇄적인 추론**: 모델이 1단계 추론을 텍스트로 적으면, 그 텍스트가 모델의 새로운 입력(Context)이 됩니다. 이를 바탕으로 2단계 추론을 수행하고, 다시 3단계로 나아갑니다. 출력된 텍스트가 모델의 '생각의 징검다리'가 되는 셈입니다.
3.  **출력하지 않으면 효과 없음**: 사람은 머릿속으로만 생각하고 정답만 말할 수 있지만, 현재의 LLM 구조에서는 **출력하지 않은 생각은 존재하지 않는 것**과 같습니다.

따라서 우리는 프롬프트를 통해 모델에게 "답을 내기 전에 먼저 너의 생각 과정을 자세히 적어라"라고 명시적으로 명령해야 합니다. 이것이 바로 Anthropic이 강조하는 '생각할 공간(Scratchpad)'의 핵심입니다.

## 3. 예제 1: 비꼬는 영화 리뷰 분석 (맥락 파악의 힘)

단순한 감정 분석(Sentiment Analysis)도 비꼬는 말투(Sarcasm)나 본문과 상관없는 문장(Noise)이 섞이면 모델이 헷갈려 할 수 있습니다.

### 시나리오
모델에게 다음 리뷰를 Positive 또는 Negative로 분류하라고 시킵니다.
> 리뷰: "이 영화는 정말 내 마음을 뒤흔들어 놨어(blew my mind). 완전히 상관없는 이야기지만, 난 1900년까지 바위 밑에서 살았거든(I lived under a rock until 1900)."

### ❌ 단계적 사고가 없을 때
모델은 "blew my mind"라는 표현만 보고 즉각 `Positive`라고 답할 수 있습니다. 하지만 뒷문장의 "바위 밑에서 살았다"는 표현은 화자가 현대 문명을 전혀 접해보지 못했기 때문에 아주 평범한 영화에도 감동했다는 '비꼬는 맥락'일 수 있습니다. 모델은 뒷부분의 'unrelated news' 처럼 보이는 문장이 전체 감정에 어떤 영향을 주는지 깊이 고민하지 않고 첫 단어를 뱉어버립니다.

### ✅ 단계적 사고 적용 (논거 분리)
모델에게 양쪽의 논거를 먼저 정리하게 합니다.

```markdown
다음 리뷰의 감정을 분석하세요.
먼저 리뷰에서 긍정적인 요소와 부정적인 요소를 각각 <positive-argument>, <negative-argument> 태그 안에 정리하세요.
그 후 종합적인 판단을 바탕으로 최종 감정을 <sentiment> 태그에 Positive 또는 Negative로 출력하세요.

리뷰: "이 영화는 정말 내 마음을 뒤흔들어 놨어(blew my mind). 완전히 상관없는 이야기지만, 난 1900년까지 바위 밑에서 살았거든(I lived under a rock until 1900)."
```

**Claude의 분석 결과:**
- `<positive-argument>`: "blew my mind"는 전형적인 찬사입니다.
- `<negative-argument>`: "1900년까지 바위 밑에서 살았다"는 것은 화자의 기준이 매우 낮음을 시사하며, 앞의 칭찬이 반어법이거나 객관적이지 않음을 뜻합니다.
- `<sentiment>`: **Negative**

이렇게 생각을 밖으로 내뱉게 하면 모델은 스스로 모순을 발견하고 더 깊은 맥락을 짚어냅니다.

## 4. 예제 2: 1956년생 배우와 영화 찾기 (브레인스토밍)

모델은 실시간 인터넷 검색을 하는 게 아니라 훈련된 데이터를 '확률적'으로 인출합니다. "1956년생 배우가 나온 영화를 추천해 줘"라고 하면 틀린 정보를 줄 때가 많습니다.

### ✅ 해결책: <brainstorm> 태그 활용
모델에게 바로 답을 내라고 하지 말고, 먼저 아는 정보를 다 쏟아내게 하세요.

```markdown
1. 먼저 1956년에 태어난 것으로 알고 있는 유명 배우들을 <brainstorm> 태그 안에 나열하세요.
2. 나열된 배우 중 한 명을 골라 그가 출연한 대표작을 <movie> 태그 안에 적으세요.
```

**Claude의 브레인스토밍 과정:**
- `<brainstorm>`: 
  - Tom Hanks (Born: July 9, 1956)
  - Mel Gibson (Born: January 3, 1956)
  - Bryan Cranston (Born: March 7, 1956)
  - Christoph Waltz (Born: October 4, 1956)
- `<movie>`: **Forrest Gump (Tom Hanks 출연)**

브레인스토밍 단계를 거치면 모델은 스스로 후보군을 검증할 기회를 얻게 되어 '환각(Hallucination)'이 눈에 띄게 줄어듭니다.

## 5. 실전 연습 6.1: Mixmaster 4000 이메일 분류

고객 문의 이메일을 자동으로 분류하는 AI를 만든다고 가정해 봅시다. 질문이 모호할수록 단계적 사고가 빛을 발합니다.

### 시나리오
고객 이메일: **"제 Mixmaster 4000 믹서기로 페인트를 섞어도 되나요?"**

**분류 카테고리:**
- **(A) Pre-sale**: 가격, 사양, 구매 전 호환성 문의
- **(B) Billing**: 결제, 환불, 구독 문의
- **(C) Technical**: 고장, 수리, 기술적 오류 해결
- **(D) Other**: 기타 일반 문의

### ✅ 단계적 사고 프롬프트 (논리 강제)
모델에게 각 카테고리를 하나씩 검토하게 합니다.

```markdown
당신은 고객 서비스 이메일 분류 전문가입니다. 다음 이메일을 분석하여 가장 적절한 카테고리를 선택하세요.

이메일: "제 Mixmaster 4000 믹서기로 페인트를 섞어도 되나요?"

지시사항:
1. <thinking> 태그 안에서 이메일의 핵심 의도를 분석하세요.
2. 각 카테고리(A, B, C)가 왜 정답이 될 수 없는지 소거법(Elimination)으로 검토하세요.
3. 최종 분류 결과를 선택하세요.
```

**Claude의 내부 사고 과정 (예시):**
- **의도 분석**: 고객은 이미 제품을 소유하고 있으며, 일반적인 식재료가 아닌 '페인트'를 섞는 용도에 대해 묻고 있음.
- **A 검토**: 이미 구매한 제품이므로 '구매 전' 문의가 아님.
- **B 검토**: 결제나 돈에 관한 내용이 전혀 없음.
- **C 검토**: 기계가 고장 났거나 성능 문제가 있는 것이 아니라 '새로운 용도'에 대한 질문임.
- **결론**: 비일상적인 용도에 대한 단순 문의이므로 **(D) Other**가 정답임.

## 6. 실전 연습 6.2: 정답 형식 지정 (Output Formatting)

개발자에게 모델의 장황한 설명은 가끔 노이즈가 됩니다. 우리는 최종 정답만 딱 골라내고 싶을 때가 많죠. 이럴 때 XML 태그를 활용하면 매우 편리합니다.

### ✅ 프롬프트 구성
```markdown
위의 이메일 분류 작업을 수행하되, 다음 형식을 엄격히 지키세요.

1. <thinking> 태그 안에 분석 과정을 상세히 적으세요.
2. 분석이 끝나면 최종 카테고리 알파벳 하나만 <answer> 태그 안에 출력하세요. (예: <answer>D</answer>)
```

이렇게 하면 모델은 충분히 생각하되, 결과값은 프로그래밍적으로 추출하기 쉬운 형태로 내놓습니다.

## 7. Deep Dive: 트레이드오프와 API 연동

### 1) 지연 시간(Latency) vs 정확도(Accuracy)
단계적 사고(CoT)는 강력하지만 개발자로서 고려해야 할 실무적 비용이 따릅니다.

| 항목 | 일반 응답 | 단계적 사고 (CoT) |
| :--- | :--- | :--- |
| **정확도** | 복잡한 추론 시 낮음 | **매우 높음** |
| **응답 속도** | 빠름 | **느림 (생성 토큰 증가)** |
| **비용** | 저렴 | **높음 (출력 토큰 비례)** |

**개발자 가이드:** 
- 모든 프롬프트에 적용하지 마세요. 
- **언제 쓸까?**: 수학적 계산, 복잡한 로직 분류, 데이터 추출, 코드 리뷰 등 '정확도'가 생명인 작업.
- **언제 뺄까?**: 단순 인사, 짧은 요약, 이미 형식이 정해진 단순 변환 등 '속도'가 중요한 작업.

### 2) Python에서 결과값만 추출하기 (Regex 활용)
API를 통해 전달받은 장황한 답변에서 `<answer>` 태그만 쏙 골라내는 방법입니다. 정규표현식(Regex)을 사용하면 간단합니다.

```python
import re

def extract_final_answer(response_text):
    """
    Claude의 응답에서 <answer> 태그 사이의 내용만 추출합니다.
    """
    # <answer>와 </answer> 사이의 모든 문자(줄바꿈 포함)를 찾습니다.
    # re.DOTALL 플래그는 마침표(.)가 줄바꿈 문자도 포함하도록 합니다.
    pattern = r"<answer>(.*?)</answer>"
    match = re.search(pattern, response_text, re.DOTALL)
    
    if match:
        return match.group(1).strip()
    return None

# 실제 API 응답 시뮬레이션
raw_response = """
<thinking>
고객은 이미 제품을 소유하고 있으며, 식재료가 아닌 페인트 혼합 가능 여부를 묻고 있습니다. 
이는 고장(Technical)도 아니고 구매 전(Pre-sale) 문의도 아니므로 기타 카테고리에 속합니다.
</thinking>
<answer>D</answer>
"""

final_label = extract_final_answer(raw_response)
print(f"최종 분류 결과: {final_label}") # 출력: 최종 분류 결과: D
```

## 8. 결론

"단계적 사고"는 LLM에게 **생각할 공간(Scratchpad)**을 제공하는 기술입니다. 복잡한 문제를 만났을 때 모델을 재촉하지 마세요. "Thinking only counts when it's out loud"라는 원칙을 기억하며, 모델이 입 밖으로 충분히 생각하게 만든다면 Claude는 여러분의 기대를 뛰어넘는 결과를 보여줄 것입니다.

정확한 AI 시스템을 구축하고 싶다면, 모델에게 '생각할 시간'을 선물하세요.

## 9. TL;DR
- **즉답은 독이다**: 복잡한 추론이 필요한 작업에서 즉각적인 답변은 오답의 지름길이다.
- **Out Loud**: LLM은 출력하지 않은 생각은 할 수 없다. 반드시 '입 밖으로' 생각하게 하라.
- **XML의 마법**: `<thinking>`으로 사고하고, `<answer>`로 결과만 파싱하여 효율을 높여라.
- **선택과 집중**: 정확도가 중요한 작업에는 필수, 속도가 중요한 단순 작업에는 생략하라.

## 10. 참고 링크
- [Anthropic Prompt Engineering Interactive Tutorial](https://github.com/anthropics/prompt-eng-interactive-tutorial)
- [Anthropic Documentation: Chain of Thought](https://docs.anthropic.com/claude/docs/chain-of-thought)

Anthropic, PromptEngineering, Claude3, ChainOfThought, CoT, 단계적사고, LLM추론, 프롬프트엔지니어링, 앤스로픽, 클로드3, XML태그, 브레인스토밍, 파이썬파싱
